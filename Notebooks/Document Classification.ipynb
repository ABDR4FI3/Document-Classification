{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_path': '../dataset/',\n",
    "    'image_size': (160, 160),# downlgaded from 224,224 to 160,160\n",
    "    'batch_size': 64,  # Increased batch size\n",
    "    'epochs': 30,      # Reduced epochs\n",
    "    'initial_learning_rate': 0.001,  # Lower initial learning rate\n",
    "    'num_classes': 10,\n",
    "    'validation_split': 0.2,\n",
    "    'weight_decay': 0.0005,\n",
    "    'dropout_rate': 0.3,\n",
    "    'early_stopping_patience': 8,  # Reduced patience\n",
    "    'min_epochs': 10   # Reduced minimum epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_images(data_path, num_samples=2):\n",
    "    \"\"\"\n",
    "    Display sample images from each category\n",
    "    \"\"\"\n",
    "    categories = os.listdir(data_path)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for idx, category in enumerate(categories):\n",
    "        category_path = os.path.join(data_path, category)\n",
    "        images = os.listdir(category_path)[:num_samples]\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            plt.subplot(len(categories), num_samples, idx * num_samples + i + 1)\n",
    "            img = Image.open(os.path.join(category_path, image))\n",
    "            plt.imshow(img)\n",
    "            plt.title(f'{category} - Sample {i+1}')\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def dataset_statistics(data_path):\n",
    "    \"\"\"\n",
    "    Display dataset statistics\n",
    "    \"\"\"\n",
    "    categories = os.listdir(data_path)\n",
    "    stats = {}\n",
    "    \n",
    "    for category in categories:\n",
    "        category_path = os.path.join(data_path, category)\n",
    "        num_images = len(os.listdir(category_path))\n",
    "        stats[category] = num_images\n",
    "    \n",
    "    # Plot statistics\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(stats.keys(), stats.values())\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Number of Images per Category')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return pd.DataFrame.from_dict(stats, orient='index', columns=['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_generators(config):\n",
    "    \"\"\"\n",
    "    More efficient data generators\n",
    "    \"\"\"\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        validation_split=config['validation_split']\n",
    "    )\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        config['data_path'],\n",
    "        target_size=config['image_size'],\n",
    "        batch_size=config['batch_size'],\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_generator = train_datagen.flow_from_directory(\n",
    "        config['data_path'],\n",
    "        target_size=config['image_size'],\n",
    "        batch_size=config['batch_size'],\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(config):\n",
    "    \"\"\"\n",
    "    Lighter model architecture for faster training\n",
    "    \"\"\"\n",
    "    # Use a smaller EfficientNet model\n",
    "    base_model = EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(*config['image_size'], 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze most layers, only unfreeze the last few\n",
    "    base_model.trainable = False\n",
    "    for layer in base_model.layers[-10:]:  # Only unfreeze last 10 layers\n",
    "        layer.trainable = True\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=l2(config['weight_decay'])),\n",
    "        layers.Dropout(config['dropout_rate']),\n",
    "        layers.Dense(config['num_classes'], activation='softmax', dtype='float32')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(train_generator):\n",
    "    \"\"\"\n",
    "    Calculate balanced class weights based on the dataset statistics\n",
    "    \"\"\"\n",
    "    class_counts = train_generator.classes.shape[0]\n",
    "    class_weights = {}\n",
    "    \n",
    "    # Using inverse class frequency with smoothing\n",
    "    for class_idx in range(train_generator.num_classes):\n",
    "        count = np.sum(train_generator.classes == class_idx)\n",
    "        weight = (1 / count) * (class_counts / train_generator.num_classes)\n",
    "        # Apply smoothing to prevent extreme weights\n",
    "        weight = np.sqrt(weight)\n",
    "        class_weights[class_idx] = weight\n",
    "    \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_generator, val_generator, config):\n",
    "    \"\"\"\n",
    "    Optimized training function\n",
    "    \"\"\"\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(\n",
    "            'best_model.keras',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=config['early_stopping_patience'],\n",
    "            restore_best_weights=True,\n",
    "            mode='min',\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Enable mixed precision\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=config['epochs'],\n",
    "        validation_data=val_generator,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_document(model, image_path, config):\n",
    "    \"\"\"\n",
    "    Make predictions on new images\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = tf.keras.preprocessing.image.load_img(\n",
    "        image_path,\n",
    "        target_size=config['image_size']\n",
    "    )\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(img_array)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(generator, config):\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        lambda: generator,\n",
    "        output_types=(tf.float32, tf.float32)\n",
    "    ).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data generators...\n",
      "Found 2788 images belonging to 10 classes.\n",
      "Found 694 images belonging to 10 classes.\n",
      "Building and compiling model...\n",
      "Model compiled successfully\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elgue\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.1703 - loss: 3.2516 - top_2_accuracy: 0.3014"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    try:\n",
    "        print(\"Creating data generators...\")\n",
    "        train_generator, val_generator = create_optimized_generators(CONFIG)\n",
    "        \n",
    "        # Set mixed precision policy\n",
    "        policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "        tf.keras.mixed_precision.set_global_policy(policy)\n",
    "        \n",
    "        # Build model\n",
    "        print(\"Building and compiling model...\")\n",
    "        model = build_model(CONFIG)\n",
    "        \n",
    "        # Explicitly compile the model with float32 metrics\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=CONFIG['initial_learning_rate'])\n",
    "        optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=[\n",
    "                tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                tf.keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy', dtype='float32')\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        print(\"Model compiled successfully\")\n",
    "        print(\"Starting training...\")\n",
    "        history = train_model(model, train_generator, val_generator, CONFIG)\n",
    "        \n",
    "        return model, history\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None, None\n",
    "# Clean up - remove any duplicate calls\n",
    "if __name__ == \"__main__\":\n",
    "    # Enable mixed precision training\n",
    "    # tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    \n",
    "    # Run main function\n",
    "    model, history = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
