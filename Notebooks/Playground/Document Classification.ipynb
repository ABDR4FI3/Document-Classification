{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_path': '../dataset/',\n",
    "    'image_size': (160, 160),# downlgaded from 224,224 to 160,160\n",
    "    'batch_size': 32,  # Increased batch size\n",
    "    'epochs': 30,      # Reduced epochs\n",
    "    'initial_learning_rate': 0.0005,  # Lower initial learning rate\n",
    "    'num_classes': 10,\n",
    "    'validation_split': 0.2,\n",
    "    'weight_decay': 0.001,\n",
    "    'dropout_rate': 0.2,\n",
    "    'early_stopping_patience': 5,  # Reduced patience\n",
    "    'min_epochs': 10   # Reduced minimum epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_images(data_path, num_samples=2):\n",
    "    \"\"\"\n",
    "    Display sample images from each category\n",
    "    \"\"\"\n",
    "    categories = os.listdir(data_path)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for idx, category in enumerate(categories):\n",
    "        category_path = os.path.join(data_path, category)\n",
    "        images = os.listdir(category_path)[:num_samples]\n",
    "        \n",
    "        for i, image in enumerate(images):\n",
    "            plt.subplot(len(categories), num_samples, idx * num_samples + i + 1)\n",
    "            img = Image.open(os.path.join(category_path, image))\n",
    "            plt.imshow(img)\n",
    "            plt.title(f'{category} - Sample {i+1}')\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def dataset_statistics(data_path):\n",
    "    \"\"\"\n",
    "    Display dataset statistics\n",
    "    \"\"\"\n",
    "    categories = os.listdir(data_path)\n",
    "    stats = {}\n",
    "    \n",
    "    for category in categories:\n",
    "        category_path = os.path.join(data_path, category)\n",
    "        num_images = len(os.listdir(category_path))\n",
    "        stats[category] = num_images\n",
    "    \n",
    "    # Plot statistics\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(stats.keys(), stats.values())\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Number of Images per Category')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return pd.DataFrame.from_dict(stats, orient='index', columns=['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_generators(config):\n",
    "    \"\"\"\n",
    "    Enhanced data generators with better augmentation\n",
    "    \"\"\"\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=config['validation_split']\n",
    "    )\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        config['data_path'],\n",
    "        target_size=config['image_size'],\n",
    "        batch_size=config['batch_size'],\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_generator = train_datagen.flow_from_directory(\n",
    "        config['data_path'],\n",
    "        target_size=config['image_size'],\n",
    "        batch_size=config['batch_size'],\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(config):\n",
    "    \"\"\"\n",
    "    Enhanced model architecture with better regularization and learning strategies\n",
    "    \"\"\"\n",
    "    # Use EfficientNetB0 with improved preprocessing\n",
    "    base_model = EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(*config['image_size'], 3)\n",
    "    )\n",
    "    \n",
    "    # Implement gradual unfreezing\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-20]:  # Freeze more layers initially\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        # Input preprocessing and augmentation\n",
    "        layers.RandomRotation(0.2),\n",
    "        layers.RandomTranslation(0.1, 0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        \n",
    "        # Base model\n",
    "        base_model,\n",
    "        \n",
    "        # Enhanced feature extraction\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # First dense block with residual connection\n",
    "        layers.Dense(512, use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Second dense block\n",
    "        layers.Dense(256, use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation('relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Output layer\n",
    "        layers.Dense(config['num_classes'], activation='softmax', dtype='float32')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(train_generator):\n",
    "    \"\"\"\n",
    "    Calculate balanced class weights based on the dataset statistics\n",
    "    \"\"\"\n",
    "    class_counts = train_generator.classes.shape[0]\n",
    "    class_weights = {}\n",
    "    \n",
    "    # Using inverse class frequency with smoothing\n",
    "    for class_idx in range(train_generator.num_classes):\n",
    "        count = np.sum(train_generator.classes == class_idx)\n",
    "        weight = (1 / count) * (class_counts / train_generator.num_classes)\n",
    "        # Apply smoothing to prevent extreme weights \n",
    "        weight = np.sqrt(weight)\n",
    "        class_weights[class_idx] = weight\n",
    "    \n",
    "    return class_weights\n",
    "\n",
    "## khaso yt7yd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_generator, val_generator, config):\n",
    "    \"\"\"\n",
    "    Enhanced training function with better learning rate schedule and callbacks\n",
    "    \"\"\"\n",
    "    # Cosine decay learning rate schedule\n",
    "    initial_learning_rate = config['initial_learning_rate']\n",
    "    decay_steps = train_generator.samples // config['batch_size'] * config['epochs']\n",
    "    lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate, decay_steps, alpha=0.1\n",
    "    )\n",
    "    \n",
    "    # Optimizer with gradient clipping\n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=lr_schedule,\n",
    "        clipnorm=1.0\n",
    "    )\n",
    "    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "    \n",
    "    # Compile with label smoothing\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "        metrics=[\n",
    "            tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "            tf.keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy', dtype='float32')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'best_model.keras',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max',\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            mode='min',\n",
    "            verbose=1\n",
    "        ),\n",
    "        # tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        #     monitor='val_loss',\n",
    "        #     factor=0.7,\n",
    "        #     patience=5,\n",
    "        #     min_lr=1e-6,\n",
    "        #     verbose=1\n",
    "        # )\n",
    "    ]\n",
    "    \n",
    "    return model.fit(\n",
    "        train_generator,\n",
    "        epochs=config['epochs'],\n",
    "        validation_data=val_generator,\n",
    "        callbacks=callbacks,\n",
    "        workers=4,\n",
    "        use_multiprocessing=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_document(model, image_path, config):\n",
    "    \"\"\"\n",
    "    Make predictions on new images\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = tf.keras.preprocessing.image.load_img(\n",
    "        image_path,\n",
    "        target_size=config['image_size']\n",
    "    )\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(img_array)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_dataset(generator, config):\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        lambda: generator,\n",
    "        output_types=(tf.float32, tf.float32)\n",
    "    ).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data generators...\n",
      "Found 2788 images belonging to 10 classes.\n",
      "Found 694 images belonging to 10 classes.\n",
      "Building and compiling model...\n",
      "Model compiled successfully\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elgue\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.1703 - loss: 3.2516 - top_2_accuracy: 0.3014\n",
      "Epoch 1: val_accuracy improved from -inf to 0.17867, saving model to best_model.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 4s/step - accuracy: 0.1709 - loss: 3.2466 - top_2_accuracy: 0.3024 - val_accuracy: 0.1787 - val_loss: 2.4174 - val_top_2_accuracy: 0.3501 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2375 - loss: 2.6494 - top_2_accuracy: 0.3980\n",
      "Epoch 2: val_accuracy did not improve from 0.17867\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 4s/step - accuracy: 0.2377 - loss: 2.6490 - top_2_accuracy: 0.3981 - val_accuracy: 0.1787 - val_loss: 2.4148 - val_top_2_accuracy: 0.3026 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2388 - loss: 2.5942 - top_2_accuracy: 0.3966\n",
      "Epoch 3: val_accuracy did not improve from 0.17867\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 4s/step - accuracy: 0.2390 - loss: 2.5931 - top_2_accuracy: 0.3968 - val_accuracy: 0.1787 - val_loss: 2.5124 - val_top_2_accuracy: 0.3415 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2689 - loss: 2.3886 - top_2_accuracy: 0.4429\n",
      "Epoch 4: val_accuracy did not improve from 0.17867\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 4s/step - accuracy: 0.2692 - loss: 2.3877 - top_2_accuracy: 0.4431 - val_accuracy: 0.1787 - val_loss: 2.4625 - val_top_2_accuracy: 0.3444 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2745 - loss: 2.3153 - top_2_accuracy: 0.4420\n",
      "Epoch 5: val_accuracy did not improve from 0.17867\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4s/step - accuracy: 0.2747 - loss: 2.3144 - top_2_accuracy: 0.4423 - val_accuracy: 0.1628 - val_loss: 2.5239 - val_top_2_accuracy: 0.3458 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3243 - loss: 2.1385 - top_2_accuracy: 0.4998\n",
      "Epoch 6: val_accuracy did not improve from 0.17867\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.3243 - loss: 2.1379 - top_2_accuracy: 0.4997 - val_accuracy: 0.1628 - val_loss: 2.4928 - val_top_2_accuracy: 0.3444 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3507 - loss: 2.0372 - top_2_accuracy: 0.5297\n",
      "Epoch 7: val_accuracy improved from 0.17867 to 0.20029, saving model to best_model.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 4s/step - accuracy: 0.3506 - loss: 2.0376 - top_2_accuracy: 0.5295 - val_accuracy: 0.2003 - val_loss: 2.4850 - val_top_2_accuracy: 0.3631 - learning_rate: 5.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3563 - loss: 1.9804 - top_2_accuracy: 0.5379\n",
      "Epoch 8: val_accuracy improved from 0.20029 to 0.24640, saving model to best_model.keras\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 4s/step - accuracy: 0.3561 - loss: 1.9811 - top_2_accuracy: 0.5378 - val_accuracy: 0.2464 - val_loss: 2.4363 - val_top_2_accuracy: 0.4280 - learning_rate: 5.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30s/step - accuracy: 0.3480 - loss: 2.0003 - top_2_accuracy: 0.5296 \n",
      "Epoch 9: val_accuracy did not improve from 0.24640\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1344s\u001b[0m 31s/step - accuracy: 0.3480 - loss: 2.0001 - top_2_accuracy: 0.5300 - val_accuracy: 0.1715 - val_loss: 2.4611 - val_top_2_accuracy: 0.3631 - learning_rate: 2.5000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3674 - loss: 1.9508 - top_2_accuracy: 0.5680\n",
      "Epoch 10: val_accuracy did not improve from 0.24640\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - accuracy: 0.3675 - loss: 1.9509 - top_2_accuracy: 0.5679 - val_accuracy: 0.2378 - val_loss: 2.3207 - val_top_2_accuracy: 0.4164 - learning_rate: 2.5000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3510 - loss: 1.9888 - top_2_accuracy: 0.5504\n",
      "Epoch 11: val_accuracy improved from 0.24640 to 0.25216, saving model to best_model.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 4s/step - accuracy: 0.3515 - loss: 1.9878 - top_2_accuracy: 0.5508 - val_accuracy: 0.2522 - val_loss: 2.2438 - val_top_2_accuracy: 0.4611 - learning_rate: 2.5000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3710 - loss: 1.9567 - top_2_accuracy: 0.5453\n",
      "Epoch 12: val_accuracy did not improve from 0.25216\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 4s/step - accuracy: 0.3711 - loss: 1.9566 - top_2_accuracy: 0.5455 - val_accuracy: 0.1744 - val_loss: 2.2727 - val_top_2_accuracy: 0.3501 - learning_rate: 2.5000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3655 - loss: 1.9390 - top_2_accuracy: 0.5698\n",
      "Epoch 13: val_accuracy did not improve from 0.25216\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 5s/step - accuracy: 0.3656 - loss: 1.9388 - top_2_accuracy: 0.5698 - val_accuracy: 0.2190 - val_loss: 2.2319 - val_top_2_accuracy: 0.4957 - learning_rate: 2.5000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3797 - loss: 1.9498 - top_2_accuracy: 0.5528\n",
      "Epoch 14: val_accuracy improved from 0.25216 to 0.30403, saving model to best_model.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 5s/step - accuracy: 0.3798 - loss: 1.9490 - top_2_accuracy: 0.5533 - val_accuracy: 0.3040 - val_loss: 2.1544 - val_top_2_accuracy: 0.4669 - learning_rate: 2.5000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4117 - loss: 1.8503 - top_2_accuracy: 0.5977\n",
      "Epoch 15: val_accuracy did not improve from 0.30403\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 4s/step - accuracy: 0.4112 - loss: 1.8510 - top_2_accuracy: 0.5974 - val_accuracy: 0.1772 - val_loss: 2.1832 - val_top_2_accuracy: 0.4755 - learning_rate: 2.5000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3936 - loss: 1.8694 - top_2_accuracy: 0.5930\n",
      "Epoch 16: val_accuracy did not improve from 0.30403\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 4s/step - accuracy: 0.3936 - loss: 1.8697 - top_2_accuracy: 0.5930 - val_accuracy: 0.1484 - val_loss: 2.4419 - val_top_2_accuracy: 0.4712 - learning_rate: 2.5000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3993 - loss: 1.8612 - top_2_accuracy: 0.5823\n",
      "Epoch 17: val_accuracy improved from 0.30403 to 0.38040, saving model to best_model.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 4s/step - accuracy: 0.3992 - loss: 1.8616 - top_2_accuracy: 0.5823 - val_accuracy: 0.3804 - val_loss: 1.9534 - val_top_2_accuracy: 0.5432 - learning_rate: 2.5000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3933 - loss: 1.8778 - top_2_accuracy: 0.5899\n",
      "Epoch 18: val_accuracy did not improve from 0.38040\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 4s/step - accuracy: 0.3933 - loss: 1.8780 - top_2_accuracy: 0.5899 - val_accuracy: 0.2983 - val_loss: 2.0985 - val_top_2_accuracy: 0.5000 - learning_rate: 2.5000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4112 - loss: 1.8512 - top_2_accuracy: 0.5956\n",
      "Epoch 19: val_accuracy did not improve from 0.38040\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 4s/step - accuracy: 0.4111 - loss: 1.8515 - top_2_accuracy: 0.5956 - val_accuracy: 0.1427 - val_loss: 2.9526 - val_top_2_accuracy: 0.2248 - learning_rate: 2.5000e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4021 - loss: 1.8791 - top_2_accuracy: 0.5955\n",
      "Epoch 20: val_accuracy improved from 0.38040 to 0.39193, saving model to best_model.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 4s/step - accuracy: 0.4022 - loss: 1.8786 - top_2_accuracy: 0.5956 - val_accuracy: 0.3919 - val_loss: 1.9374 - val_top_2_accuracy: 0.5317 - learning_rate: 2.5000e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4086 - loss: 1.8263 - top_2_accuracy: 0.6174\n",
      "Epoch 21: val_accuracy did not improve from 0.39193\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 4s/step - accuracy: 0.4086 - loss: 1.8267 - top_2_accuracy: 0.6173 - val_accuracy: 0.1787 - val_loss: 3.2583 - val_top_2_accuracy: 0.2507 - learning_rate: 2.5000e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4158 - loss: 1.8494 - top_2_accuracy: 0.6139\n",
      "Epoch 22: val_accuracy did not improve from 0.39193\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 4s/step - accuracy: 0.4155 - loss: 1.8495 - top_2_accuracy: 0.6140 - val_accuracy: 0.3401 - val_loss: 2.0955 - val_top_2_accuracy: 0.5115 - learning_rate: 2.5000e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3851 - loss: 1.8565 - top_2_accuracy: 0.6093\n",
      "Epoch 23: val_accuracy did not improve from 0.39193\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4s/step - accuracy: 0.3854 - loss: 1.8565 - top_2_accuracy: 0.6093 - val_accuracy: 0.3790 - val_loss: 1.9289 - val_top_2_accuracy: 0.5202 - learning_rate: 2.5000e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3930 - loss: 1.8451 - top_2_accuracy: 0.6049\n",
      "Epoch 24: val_accuracy improved from 0.39193 to 0.44236, saving model to best_model.keras\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 4s/step - accuracy: 0.3931 - loss: 1.8447 - top_2_accuracy: 0.6051 - val_accuracy: 0.4424 - val_loss: 1.9631 - val_top_2_accuracy: 0.5908 - learning_rate: 2.5000e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4254 - loss: 1.7924 - top_2_accuracy: 0.6158\n",
      "Epoch 25: val_accuracy did not improve from 0.44236\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 4s/step - accuracy: 0.4252 - loss: 1.7929 - top_2_accuracy: 0.6158 - val_accuracy: 0.2594 - val_loss: 2.1888 - val_top_2_accuracy: 0.4683 - learning_rate: 2.5000e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4171 - loss: 1.7958 - top_2_accuracy: 0.6143\n",
      "Epoch 26: val_accuracy did not improve from 0.44236\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 8s/step - accuracy: 0.4169 - loss: 1.7965 - top_2_accuracy: 0.6140 - val_accuracy: 0.3343 - val_loss: 2.1128 - val_top_2_accuracy: 0.4914 - learning_rate: 2.5000e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4123 - loss: 1.7886 - top_2_accuracy: 0.6207\n",
      "Epoch 27: val_accuracy did not improve from 0.44236\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 8s/step - accuracy: 0.4124 - loss: 1.7886 - top_2_accuracy: 0.6207 - val_accuracy: 0.3977 - val_loss: 1.8957 - val_top_2_accuracy: 0.5764 - learning_rate: 1.2500e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4282 - loss: 1.7900 - top_2_accuracy: 0.6259\n",
      "Epoch 28: val_accuracy did not improve from 0.44236\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 8s/step - accuracy: 0.4281 - loss: 1.7900 - top_2_accuracy: 0.6257 - val_accuracy: 0.1513 - val_loss: 2.6183 - val_top_2_accuracy: 0.4539 - learning_rate: 1.2500e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4492 - loss: 1.7505 - top_2_accuracy: 0.6438\n",
      "Epoch 29: val_accuracy did not improve from 0.44236\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 7s/step - accuracy: 0.4490 - loss: 1.7509 - top_2_accuracy: 0.6436 - val_accuracy: 0.4294 - val_loss: 1.9038 - val_top_2_accuracy: 0.5634 - learning_rate: 1.2500e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4439 - loss: 1.7501 - top_2_accuracy: 0.6435\n",
      "Epoch 30: val_accuracy improved from 0.44236 to 0.45533, saving model to best_model.keras\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 4s/step - accuracy: 0.4441 - loss: 1.7500 - top_2_accuracy: 0.6436 - val_accuracy: 0.4553 - val_loss: 1.9018 - val_top_2_accuracy: 0.5937 - learning_rate: 1.2500e-04\n",
      "Restoring model weights from the end of the best epoch: 27.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main():\n",
    "    try:\n",
    "        print(\"Creating data generators...\")\n",
    "        train_generator, val_generator = create_optimized_generators(CONFIG)\n",
    "        \n",
    "        # Set mixed precision policy\n",
    "        policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "        tf.keras.mixed_precision.set_global_policy(policy)\n",
    "        \n",
    "        # Build model\n",
    "        print(\"Building and compiling model...\")\n",
    "        model = build_model(CONFIG)\n",
    "        \n",
    "        # Explicitly compile the model with float32 metrics\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=CONFIG['initial_learning_rate'])\n",
    "        optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=[\n",
    "                tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                tf.keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy', dtype='float32')\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        print(\"Model compiled successfully\")\n",
    "        print(\"Starting training...\")\n",
    "        history = train_model(model, train_generator, val_generator, CONFIG)\n",
    "        \n",
    "        return model, history\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None, None\n",
    "# Clean up - remove any duplicate calls\n",
    "if __name__ == \"__main__\":\n",
    "    # Enable mixed precision training\n",
    "    # tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    \n",
    "    # Run main function\n",
    "    model, history = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OPTIMIZED_CONFIG = {\n",
    "    'data_path': '/kaggle/input/scanned-images-dataset-for-ocr-and-vlm-finetuning/dataset',\n",
    "    'image_size': (128, 128),\n",
    "    'batch_size': 32,\n",
    "    'epochs': 50,\n",
    "    'initial_learning_rate': 0.0001,  # Reduced learning rate\n",
    "    'num_classes': 10,\n",
    "    'validation_split': 0.2,\n",
    "    'weight_decay': 0.0005,  # Reduced weight decay\n",
    "    'dropout_rate': 0.3,    # Reduced dropout\n",
    "    'early_stopping_patience': 10  # Increased patience\n",
    "}\n",
    "\n",
    "def create_data_generators(config):\n",
    "    \"\"\"Create training and validation data generators\"\"\"\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        validation_split=config['validation_split'],\n",
    "        rotation_range=15,        # Reduced augmentation\n",
    "        width_shift_range=0.1,    # Reduced augmentation\n",
    "        height_shift_range=0.1,   # Reduced augmentation\n",
    "        zoom_range=0.1,          # Reduced augmentation\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        config['data_path'],\n",
    "        target_size=config['image_size'],\n",
    "        batch_size=config['batch_size'],\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        config['data_path'],\n",
    "        target_size=config['image_size'],\n",
    "        batch_size=config['batch_size'],\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Make generators repeat indefinitely\n",
    "    return train_generator, validation_generator\n",
    "\n",
    "def create_model(config):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(*config['image_size'], 3)),\n",
    "        \n",
    "        # Simplified architecture with gradual scaling\n",
    "        layers.Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(config['weight_decay'])),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(64, (3, 3), padding='same', activation='relu',\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(config['weight_decay'])),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), padding='same', activation='relu',\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(config['weight_decay'])),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        \n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(128, activation='relu',\n",
    "                    kernel_regularizer=tf.keras.regularizers.l2(config['weight_decay'])),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(config['dropout_rate']),\n",
    "        layers.Dense(config['num_classes'], activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def main(config):\n",
    "    train_generator, validation_generator = create_data_generators(config)\n",
    "    \n",
    "    # Calculate steps correctly\n",
    "    steps_per_epoch = train_generator.samples // config['batch_size']\n",
    "    validation_steps = validation_generator.samples // config['batch_size']\n",
    "    \n",
    "    model = create_model(config)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(\n",
    "        config['initial_learning_rate'],\n",
    "        clipnorm=1.0  # Added gradient clipping\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=config['early_stopping_patience'],\n",
    "            restore_best_weights=True,\n",
    "            min_delta=0.001  # Added minimum change threshold\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,     # More gradual reduction\n",
    "            patience=3,\n",
    "            min_lr=1e-6\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='best_model.keras',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=config['epochs'],\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, history = main(OPTIMIZED_CONFIG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
